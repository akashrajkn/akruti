{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb7748de930>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_MSD(msd):\n",
    "    '''\n",
    "    Process msd in the input sentence\n",
    "    Args:\n",
    "        msd: string containing different MSDs\n",
    "    Returns:\n",
    "        out: dict with different msds\n",
    "    '''\n",
    "    \n",
    "    out = {}\n",
    "    msds = msd.strip().split(',')\n",
    "\n",
    "    for m in msds:\n",
    "        current = m.strip().split('=')\n",
    "        out[current[0]] = current[1]\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/task1_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f7320aacbd20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mout\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/task1_test'"
     ]
    }
   ],
   "source": [
    "path = '../data/task1_test'\n",
    "\n",
    "out  = []\n",
    "\n",
    "with open(path, 'r', encoding='utf-8') as f:\n",
    "    source = f.read()\n",
    "    \n",
    "sentences = source.strip().split('\\n')\n",
    "\n",
    "for sentence in sentences:\n",
    "    line = sentence.strip().split('\\t')\n",
    "    \n",
    "    if len(line) > 3:\n",
    "        print('Something wrong with line: {}'.format(sentence))\n",
    "        continue\n",
    "    \n",
    "    current_word = {\n",
    "        'lemma'      : line[0],\n",
    "        'MSD'        : process_MSD(line[1]),\n",
    "        'target_form': line[2]        \n",
    "    }\n",
    "    \n",
    "    out.append(current_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(out[0])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/pickles/task3_test.pkl', 'rb') as f:\n",
    "    n_out = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source_form': 'playing',\n",
       "  'MSD': {'pos': 'verb', 'tense': 'present', 'mod': 'ind'},\n",
       "  'target_form': 'played'},\n",
       " {'source_form': 'trivial',\n",
       "  'MSD': {'pos': 'adj', 'color': 'neg'},\n",
       "  'target_form': 'untrivial'},\n",
       " {'source_form': 'decided',\n",
       "  'MSD': {'pos': 'verb', 'tense': 'past', 'mod': 'cc'},\n",
       "  'target_form': 'decide'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The': 0, 'dog': 1, 'ate': 2, 'the': 3, 'apple': 4, 'Everybody': 5, 'read': 6, 'that': 7, 'book': 8}\n"
     ]
    }
   ],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "training_data = [\n",
    "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
    "]\n",
    "word_to_ix = {}\n",
    "for sent, tags in training_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "print(word_to_ix)\n",
    "tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2}\n",
    "\n",
    "# These will usually be more like 32 or 64 dimensional.\n",
    "# We will keep them small, so we can see how the weights change as we train.\n",
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path):\n",
    "    '''\n",
    "    load pickle File\n",
    "    Args:\n",
    "        path: file path\n",
    "    Returns:\n",
    "        out : pickle loaded\n",
    "    '''\n",
    "\n",
    "    with open(path, 'rb') as f:\n",
    "        out = pickle.load(f)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pos': 0, 'tense': 1, 'mod': 2, 'color': 3}\n",
      "---\n",
      "{0: {'None': 0, 'verb': 1, 'adj': 2}, 1: {'None': 0, 'present': 1, 'past': 2}, 2: {'None': 0, 'ind': 1, 'cc': 2}, 3: {'None': 0, 'neg': 1}}\n",
      "---\n",
      "[{'source_form': 'playing', 'MSD': {'pos': 'verb', 'tense': 'present', 'mod': 'ind'}, 'target_form': 'played'}, {'source_form': 'trivial', 'MSD': {'pos': 'adj', 'color': 'neg'}, 'target_form': 'untrivial'}, {'source_form': 'decided', 'MSD': {'pos': 'verb', 'tense': 'past', 'mod': 'cc'}, 'target_form': 'decide'}]\n"
     ]
    }
   ],
   "source": [
    "with open('../data/pickles/desc_2_idx', 'rb') as f:\n",
    "    desc_2_idx = pickle.load(f)\n",
    "    \n",
    "print(desc_2_idx)\n",
    "print(\"---\")\n",
    "\n",
    "with open('../data/pickles/msd_options', 'rb') as f:\n",
    "    msd_options = pickle.load(f)\n",
    "    \n",
    "print(msd_options)\n",
    "print(\"---\")\n",
    "\n",
    "with open('../data/pickles/task3_test.pkl', 'rb') as f:\n",
    "    task3_test = pickle.load(f)\n",
    "\n",
    "print(task3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_msd(msd, idx_2_desc, msd_options):\n",
    "    '''\n",
    "    msd: {'pos': 'verb', 'tense': 'present', 'mod': 'ind'}\n",
    "\n",
    "    output: [0, 1, 2, 0, 0, ...]\n",
    "    '''\n",
    "    label_len = len(idx_2_desc)\n",
    "    k_output  = []\n",
    "\n",
    "    for i in range(label_len):\n",
    "        desc  = idx_2_desc[i]\n",
    "        opt   = msd.get(desc)\n",
    "        types = msd_options[i]\n",
    "\n",
    "        if opt is None:\n",
    "            k_output.append(to_categorical([0], num_classes=len(types))[0])\n",
    "            continue\n",
    "\n",
    "        k_output.append(to_categorical([types[opt]], num_classes=len(types))[0])\n",
    "\n",
    "    return np.concatenate(k_output, axis=0)\n",
    "\n",
    "def prepare_sequence(sequence, char_2_idx, max_seq_len):\n",
    "    '''\n",
    "    Append <END> to each sequence and Pad with <PAD>\n",
    "    '''\n",
    "    output = []\n",
    "\n",
    "    for char in sequence:\n",
    "        output.append(char_2_idx[char])\n",
    "\n",
    "    output.append(char_2_idx['<END>'])\n",
    "\n",
    "    while len(output) < max_seq_len:\n",
    "        output.append(char_2_idx['<PAD>'])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_2_desc  = load_file('../data/pickles/idx_2_desc')\n",
    "char_2_idx  = load_file('../data/pickles/char_2_idx')\n",
    "msd_options = load_file('../data/pickles/msd_options')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels    : [0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0.]\n",
      "data_test : [0, 1, 2, 3, 4, 5, 6, 14, 15, 15]\n",
      "vocab size: 16\n"
     ]
    }
   ],
   "source": [
    "# msd = {'pos': 'verb', 'tense': 'present', 'mod': 'ind'}\n",
    "# msd = {'pos': 'adj', 'color': 'neg'}\n",
    "msd       = {'pos': 'verb', 'tense': 'past', 'mod': 'cc'}\n",
    "labels    = prepare_msd(msd, idx_2_desc, msd_options)\n",
    "data_test = prepare_sequence('playing', char_2_idx, 10)\n",
    "\n",
    "print('labels    : {}'.format(labels))\n",
    "print('data_test : {}'.format(data_test))\n",
    "print('vocab size: {}'.format(len(char_2_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 16])\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([1, 10, 16])\n"
     ]
    }
   ],
   "source": [
    "x_s = torch.from_numpy(to_categorical(data_test, num_classes=len(char_2_idx)))\n",
    "print(x_s.size())\n",
    "print(x_s[0])\n",
    "\n",
    "x_s = torch.unsqueeze(x_s, 0)\n",
    "print(x_s.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
