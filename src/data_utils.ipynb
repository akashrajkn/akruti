{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_task2_files(filepath):\n",
    "#     with open(filepath, 'r', encoding='utf-8') as f:\n",
    "#         source = f.read()\n",
    "\n",
    "#     out       = []\n",
    "#     sentences = source.strip().split('\\n')\n",
    "\n",
    "#     for sentence in sentences:\n",
    "#         line  = sentence.strip().split('\\t')\n",
    "#         line  = line[1:4]\n",
    "#         out.append('\\t'.join(line))\n",
    "\n",
    "#     with open(filepath.replace('task2', 'task2p'), 'w+') as f:\n",
    "#         f.write('\\n'.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_path = '../data/files/'\n",
    "\n",
    "# for lang in ['arabic', 'finnish', 'georgian', 'german', 'hungarian', 'maltese', 'navajo', 'russian', 'spanish', 'turkish']:\n",
    "    \n",
    "#     n_p = common_path + '{}-task2-'.format(lang)\n",
    "    \n",
    "#     for t in ['train', 'test', 'dev']:\n",
    "#         filepath = n_p + t\n",
    "        \n",
    "#         process_task2_files(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0                                 1          2\n",
      "0     play    pos=verb,tense=present,mod=ind     played\n",
      "1  trivial                 pos=adj,color=neg  untrivial\n",
      "2  decided        pos=verb,tense=past,mod=cc     decide\n",
      "0   played    pos=verb,tense=present,mod=ind       play\n",
      "1    files  pos=adj,color=pos,tense=whatever      files\n",
      "2  running         pos=verb,tense=now,mod=pp        run\n"
     ]
    }
   ],
   "source": [
    "from dataset import Vocabulary, MorphologyDatasetTask3\n",
    "\n",
    "\n",
    "vocab      = Vocabulary('LANG')\n",
    "morph_data = MorphologyDatasetTask3(test=False, language='LANG', vocab=vocab)\n",
    "dataloader = DataLoader(morph_data, batch_size=1, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(i_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vocab.char_2_idx))\n",
    "print(len(vocab.desc_2_idx))\n",
    "# print(vocab.idx_2_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "# a = a.permute(1, 0)\n",
    "print(a.size()[0])\n",
    "# a = a.unsqueeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../../results/attentions.pkl', 'rb') as f:\n",
    "    attentions = pickle.load(f)\n",
    "    \n",
    "attentions = attentions.squeeze(1)\n",
    "\n",
    "plt.matshow(attentions)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import *\n",
    "from helper import load_file\n",
    "\n",
    "idx_2_char = load_file('../data/pickles/{}-idx_2_char'.format('english'))\n",
    "char_2_idx = load_file('../data/pickles/{}-char_2_idx'.format('english'))\n",
    "idx_2_desc = load_file('../data/pickles/{}-idx_2_desc'.format('english'))\n",
    "desc_2_idx = load_file('../data/pickles/{}-desc_2_idx'.format('english'))\n",
    "# msd_types  = load_file('../data/pickles/{}-msd_options'.format('english'))  # label types\n",
    "\n",
    "print(char_2_idx)\n",
    "\n",
    "\n",
    "morph_data = MorphologyDatasetTask3(csv_file='../data/files/english-task3-test', language='english', \n",
    "                                    root_dir='../data/files')\n",
    "morph_data.set_vocabulary(char_2_idx, idx_2_char, desc_2_idx, idx_2_desc, None)\n",
    "\n",
    "dataloader = DataLoader(morph_data, batch_size=1, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(sample_batched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_MSD(msd):\n",
    "    '''\n",
    "    Process msd in the input sentence\n",
    "    Args:\n",
    "        msd: string containing different MSDs\n",
    "    Returns:\n",
    "        out: dict with different msds\n",
    "    '''\n",
    "    \n",
    "    out = {}\n",
    "    msds = msd.strip().split(',')\n",
    "\n",
    "    for m in msds:\n",
    "        current = m.strip().split('=')\n",
    "        out[current[0]] = current[1]\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/task1_test'\n",
    "\n",
    "out  = []\n",
    "\n",
    "with open(path, 'r', encoding='utf-8') as f:\n",
    "    source = f.read()\n",
    "    \n",
    "sentences = source.strip().split('\\n')\n",
    "\n",
    "for sentence in sentences:\n",
    "    line = sentence.strip().split('\\t')\n",
    "    \n",
    "    if len(line) > 3:\n",
    "        print('Something wrong with line: {}'.format(sentence))\n",
    "        continue\n",
    "    \n",
    "    current_word = {\n",
    "        'lemma'      : line[0],\n",
    "        'MSD'        : process_MSD(line[1]),\n",
    "        'target_form': line[2]        \n",
    "    }\n",
    "    \n",
    "    out.append(current_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(out[0])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/pickles/task3_test.pkl', 'rb') as f:\n",
    "    n_out = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "training_data = [\n",
    "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
    "]\n",
    "word_to_ix = {}\n",
    "for sent, tags in training_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "print(word_to_ix)\n",
    "tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2}\n",
    "\n",
    "# These will usually be more like 32 or 64 dimensional.\n",
    "# We will keep them small, so we can see how the weights change as we train.\n",
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path):\n",
    "    '''\n",
    "    load pickle File\n",
    "    Args:\n",
    "        path: file path\n",
    "    Returns:\n",
    "        out : pickle loaded\n",
    "    '''\n",
    "\n",
    "    with open(path, 'rb') as f:\n",
    "        out = pickle.load(f)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/pickles/desc_2_idx', 'rb') as f:\n",
    "    desc_2_idx = pickle.load(f)\n",
    "    \n",
    "print(desc_2_idx)\n",
    "print(\"---\")\n",
    "\n",
    "with open('../data/pickles/msd_options', 'rb') as f:\n",
    "    msd_options = pickle.load(f)\n",
    "    \n",
    "print(msd_options)\n",
    "print(\"---\")\n",
    "\n",
    "with open('../data/pickles/task3_test.pkl', 'rb') as f:\n",
    "    task3_test = pickle.load(f)\n",
    "\n",
    "print(task3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_msd(msd, idx_2_desc, msd_options):\n",
    "    '''\n",
    "    msd: {'pos': 'verb', 'tense': 'present', 'mod': 'ind'}\n",
    "\n",
    "    output: [0, 1, 2, 0, 0, ...]\n",
    "    '''\n",
    "    label_len = len(idx_2_desc)\n",
    "    k_output  = []\n",
    "\n",
    "    for i in range(label_len):\n",
    "        desc  = idx_2_desc[i]\n",
    "        opt   = msd.get(desc)\n",
    "        types = msd_options[i]\n",
    "\n",
    "        if opt is None:\n",
    "            k_output.append(to_categorical([0], num_classes=len(types))[0])\n",
    "            continue\n",
    "\n",
    "        k_output.append(to_categorical([types[opt]], num_classes=len(types))[0])\n",
    "\n",
    "    return np.concatenate(k_output, axis=0)\n",
    "\n",
    "def prepare_sequence(sequence, char_2_idx, max_seq_len):\n",
    "    '''\n",
    "    Append <END> to each sequence and Pad with <PAD>\n",
    "    '''\n",
    "    output = []\n",
    "\n",
    "    for char in sequence:\n",
    "        output.append(char_2_idx[char])\n",
    "\n",
    "    output.append(char_2_idx['<END>'])\n",
    "\n",
    "    while len(output) < max_seq_len:\n",
    "        output.append(char_2_idx['<PAD>'])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_2_desc  = load_file('../data/pickles/idx_2_desc')\n",
    "char_2_idx  = load_file('../data/pickles/char_2_idx')\n",
    "msd_options = load_file('../data/pickles/msd_options')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# msd = {'pos': 'verb', 'tense': 'present', 'mod': 'ind'}\n",
    "# msd = {'pos': 'adj', 'color': 'neg'}\n",
    "msd       = {'pos': 'verb', 'tense': 'past', 'mod': 'cc'}\n",
    "labels    = prepare_msd(msd, idx_2_desc, msd_options)\n",
    "data_test = prepare_sequence('playing', char_2_idx, 10)\n",
    "\n",
    "print('labels    : {}'.format(labels))\n",
    "print('data_test : {}'.format(data_test))\n",
    "print('vocab size: {}'.format(len(char_2_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_s = torch.from_numpy(to_categorical(data_test, num_classes=len(char_2_idx)))\n",
    "print(x_s.size())\n",
    "print(x_s[0])\n",
    "\n",
    "# x_s = torch.unsqueeze(x_s, 0)\n",
    "# print(x_s.size())\n",
    "\n",
    "\n",
    "print(F.log_softmax(x_s, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.distributions.categorical.Categorical(torch.tensor([ 0.25, 0.25, 0.25, 0.25 ]))\n",
    "\n",
    "sample = m.sample()\n",
    "\n",
    "print(m.log_prob(sample))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
