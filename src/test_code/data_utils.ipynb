{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f717c036550>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x706.909 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('../../results/attentions.pkl', 'rb') as f:\n",
    "    attentions = pickle.load(f)\n",
    "    \n",
    "attentions = attentions.squeeze(1)\n",
    "\n",
    "plt.matshow(attentions)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "playing                                  trivial\n",
      "pos=verb,tense=past,mod=ind    pos=adj,color=neg\n",
      "played                                 untrivial\n",
      "Name: 0, dtype: object\n",
      "{'source_form': 'trivial', 'msd': pos=verb,tense=past,mod=ind    pos=adj,color=neg\n",
      "Name: 0, dtype: object, 'target_form': 'untrivial'}\n",
      "hello\n",
      "playing                                              decided\n",
      "pos=verb,tense=past,mod=ind    pos=verb,tense=present,mod=cc\n",
      "played                                                decide\n",
      "Name: 1, dtype: object\n",
      "{'source_form': 'decided', 'msd': pos=verb,tense=past,mod=ind    pos=verb,tense=present,mod=cc\n",
      "Name: 1, dtype: object, 'target_form': 'decide'}\n"
     ]
    }
   ],
   "source": [
    "from dataset import *\n",
    "\n",
    "morph_data = MorphologyDatasetTask3(csv_file='../data/files/english_csv_test.csv', language='english', \n",
    "                                    root_dir='../data/files')\n",
    "\n",
    "for i in range(len(morph_data)):\n",
    "    sample = morph_data[i]\n",
    "    \n",
    "    print(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_MSD(msd):\n",
    "    '''\n",
    "    Process msd in the input sentence\n",
    "    Args:\n",
    "        msd: string containing different MSDs\n",
    "    Returns:\n",
    "        out: dict with different msds\n",
    "    '''\n",
    "    \n",
    "    out = {}\n",
    "    msds = msd.strip().split(',')\n",
    "\n",
    "    for m in msds:\n",
    "        current = m.strip().split('=')\n",
    "        out[current[0]] = current[1]\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/task1_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f7320aacbd20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mout\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/task1_test'"
     ]
    }
   ],
   "source": [
    "path = '../data/task1_test'\n",
    "\n",
    "out  = []\n",
    "\n",
    "with open(path, 'r', encoding='utf-8') as f:\n",
    "    source = f.read()\n",
    "    \n",
    "sentences = source.strip().split('\\n')\n",
    "\n",
    "for sentence in sentences:\n",
    "    line = sentence.strip().split('\\t')\n",
    "    \n",
    "    if len(line) > 3:\n",
    "        print('Something wrong with line: {}'.format(sentence))\n",
    "        continue\n",
    "    \n",
    "    current_word = {\n",
    "        'lemma'      : line[0],\n",
    "        'MSD'        : process_MSD(line[1]),\n",
    "        'target_form': line[2]        \n",
    "    }\n",
    "    \n",
    "    out.append(current_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(out[0])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/pickles/task3_test.pkl', 'rb') as f:\n",
    "    n_out = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source_form': 'playing',\n",
       "  'MSD': {'pos': 'verb', 'tense': 'present', 'mod': 'ind'},\n",
       "  'target_form': 'played'},\n",
       " {'source_form': 'trivial',\n",
       "  'MSD': {'pos': 'adj', 'color': 'neg'},\n",
       "  'target_form': 'untrivial'},\n",
       " {'source_form': 'decided',\n",
       "  'MSD': {'pos': 'verb', 'tense': 'past', 'mod': 'cc'},\n",
       "  'target_form': 'decide'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The': 0, 'dog': 1, 'ate': 2, 'the': 3, 'apple': 4, 'Everybody': 5, 'read': 6, 'that': 7, 'book': 8}\n"
     ]
    }
   ],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "training_data = [\n",
    "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
    "]\n",
    "word_to_ix = {}\n",
    "for sent, tags in training_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "print(word_to_ix)\n",
    "tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2}\n",
    "\n",
    "# These will usually be more like 32 or 64 dimensional.\n",
    "# We will keep them small, so we can see how the weights change as we train.\n",
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path):\n",
    "    '''\n",
    "    load pickle File\n",
    "    Args:\n",
    "        path: file path\n",
    "    Returns:\n",
    "        out : pickle loaded\n",
    "    '''\n",
    "\n",
    "    with open(path, 'rb') as f:\n",
    "        out = pickle.load(f)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pos': 0, 'tense': 1, 'mod': 2, 'color': 3}\n",
      "---\n",
      "{0: {'None': 0, 'verb': 1, 'adj': 2}, 1: {'None': 0, 'present': 1, 'past': 2}, 2: {'None': 0, 'ind': 1, 'cc': 2}, 3: {'None': 0, 'neg': 1}}\n",
      "---\n",
      "[{'source_form': 'playing', 'MSD': {'pos': 'verb', 'tense': 'present', 'mod': 'ind'}, 'target_form': 'played'}, {'source_form': 'trivial', 'MSD': {'pos': 'adj', 'color': 'neg'}, 'target_form': 'untrivial'}, {'source_form': 'decided', 'MSD': {'pos': 'verb', 'tense': 'past', 'mod': 'cc'}, 'target_form': 'decide'}]\n"
     ]
    }
   ],
   "source": [
    "with open('../data/pickles/desc_2_idx', 'rb') as f:\n",
    "    desc_2_idx = pickle.load(f)\n",
    "    \n",
    "print(desc_2_idx)\n",
    "print(\"---\")\n",
    "\n",
    "with open('../data/pickles/msd_options', 'rb') as f:\n",
    "    msd_options = pickle.load(f)\n",
    "    \n",
    "print(msd_options)\n",
    "print(\"---\")\n",
    "\n",
    "with open('../data/pickles/task3_test.pkl', 'rb') as f:\n",
    "    task3_test = pickle.load(f)\n",
    "\n",
    "print(task3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_msd(msd, idx_2_desc, msd_options):\n",
    "    '''\n",
    "    msd: {'pos': 'verb', 'tense': 'present', 'mod': 'ind'}\n",
    "\n",
    "    output: [0, 1, 2, 0, 0, ...]\n",
    "    '''\n",
    "    label_len = len(idx_2_desc)\n",
    "    k_output  = []\n",
    "\n",
    "    for i in range(label_len):\n",
    "        desc  = idx_2_desc[i]\n",
    "        opt   = msd.get(desc)\n",
    "        types = msd_options[i]\n",
    "\n",
    "        if opt is None:\n",
    "            k_output.append(to_categorical([0], num_classes=len(types))[0])\n",
    "            continue\n",
    "\n",
    "        k_output.append(to_categorical([types[opt]], num_classes=len(types))[0])\n",
    "\n",
    "    return np.concatenate(k_output, axis=0)\n",
    "\n",
    "def prepare_sequence(sequence, char_2_idx, max_seq_len):\n",
    "    '''\n",
    "    Append <END> to each sequence and Pad with <PAD>\n",
    "    '''\n",
    "    output = []\n",
    "\n",
    "    for char in sequence:\n",
    "        output.append(char_2_idx[char])\n",
    "\n",
    "    output.append(char_2_idx['<END>'])\n",
    "\n",
    "    while len(output) < max_seq_len:\n",
    "        output.append(char_2_idx['<PAD>'])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_2_desc  = load_file('../data/pickles/idx_2_desc')\n",
    "char_2_idx  = load_file('../data/pickles/char_2_idx')\n",
    "msd_options = load_file('../data/pickles/msd_options')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels    : [0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0.]\n",
      "data_test : [0, 1, 2, 3, 4, 5, 6, 14, 15, 15]\n",
      "vocab size: 16\n"
     ]
    }
   ],
   "source": [
    "# msd = {'pos': 'verb', 'tense': 'present', 'mod': 'ind'}\n",
    "# msd = {'pos': 'adj', 'color': 'neg'}\n",
    "msd       = {'pos': 'verb', 'tense': 'past', 'mod': 'cc'}\n",
    "labels    = prepare_msd(msd, idx_2_desc, msd_options)\n",
    "data_test = prepare_sequence('playing', char_2_idx, 10)\n",
    "\n",
    "print('labels    : {}'.format(labels))\n",
    "print('data_test : {}'.format(data_test))\n",
    "print('vocab size: {}'.format(len(char_2_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 16])\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([[-1.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746,\n",
      "         -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746],\n",
      "        [-2.8746, -1.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746,\n",
      "         -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746],\n",
      "        [-2.8746, -2.8746, -1.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746,\n",
      "         -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746],\n",
      "        [-2.8746, -2.8746, -2.8746, -1.8746, -2.8746, -2.8746, -2.8746, -2.8746,\n",
      "         -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746],\n",
      "        [-2.8746, -2.8746, -2.8746, -2.8746, -1.8746, -2.8746, -2.8746, -2.8746,\n",
      "         -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746],\n",
      "        [-2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -1.8746, -2.8746, -2.8746,\n",
      "         -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746],\n",
      "        [-2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -1.8746, -2.8746,\n",
      "         -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746],\n",
      "        [-2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746,\n",
      "         -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -1.8746, -2.8746],\n",
      "        [-2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746,\n",
      "         -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -1.8746],\n",
      "        [-2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746,\n",
      "         -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -2.8746, -1.8746]])\n"
     ]
    }
   ],
   "source": [
    "x_s = torch.from_numpy(to_categorical(data_test, num_classes=len(char_2_idx)))\n",
    "print(x_s.size())\n",
    "print(x_s[0])\n",
    "\n",
    "# x_s = torch.unsqueeze(x_s, 0)\n",
    "# print(x_s.size())\n",
    "\n",
    "\n",
    "print(F.log_softmax(x_s, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.3863)\n"
     ]
    }
   ],
   "source": [
    "m = torch.distributions.categorical.Categorical(torch.tensor([ 0.25, 0.25, 0.25, 0.25 ]))\n",
    "\n",
    "sample = m.sample()\n",
    "\n",
    "print(m.log_prob(sample))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
